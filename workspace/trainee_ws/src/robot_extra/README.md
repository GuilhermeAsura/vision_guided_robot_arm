# Robot Extra Challenges (IK & Depth Estimation)

Este pacote cont√©m as implementa√ß√µes avan√ßadas do projeto, focando em desafios de percep√ß√£o 3D e controle aut√¥nomo baseado em coordenadas espaciais. Ele estende as capacidades do manipulador UR5e para entender a profundidade de objetos usando uma c√¢mera monocular e calcular trajet√≥rias usando Cinem√°tica Inversa (IK).

## üéØ Objetivos

1.  **Estimativa de Profundidade Monocular:** Calcular a dist√¢ncia ($Z$) de um objeto conhecido (bola) baseando-se apenas no seu tamanho em pixels na imagem (Modelo Pinhole).
2.  **Transforma√ß√£o de Coordenadas (TF2):** Converter coordenadas do referencial da C√¢mera (Optical Frame) para o referencial da Base do Rob√¥ (World Frame).
3.  **Cinem√°tica Inversa (IK):** Utilizar a biblioteca `ikpy` para mover o efetuador do rob√¥ para uma coordenada $(x, y, z)$ espec√≠fica no espa√ßo.

## üìÇ Estrutura do Pacote

```text
robot_extra/
‚îú‚îÄ‚îÄ launch/
‚îÇ   ‚îú‚îÄ‚îÄ extra_challenge.launch.py  # Lan√ßa Visual Servoing com profundidade
‚îÇ   ‚îú‚îÄ‚îÄ ik_challenge.launch.py     # O MAIS COMPLETO: IK + TF + URDF + Vis√£o
‚îÇ   ‚îî‚îÄ‚îÄ depth_estimator.launch.py  # Apenas o n√≥ de vis√£o (debug)
‚îú‚îÄ‚îÄ robot_extra/
‚îÇ   ‚îú‚îÄ‚îÄ depth_estimator_node.py    # Percep√ß√£o 3D e Transformada TF
‚îÇ   ‚îú‚îÄ‚îÄ ik_controller_node.py      # Controlador IK (Inverse Kinematics)
‚îÇ   ‚îî‚îÄ‚îÄ robot_controller_node.py   # Controlador P (Visual Servoing Simples)
‚îú‚îÄ‚îÄ package.xml
‚îî‚îÄ‚îÄ setup.py
````

## ‚öôÔ∏è Depend√™ncias

Este pacote faz uso intensivo de bibliotecas matem√°ticas e de transforma√ß√£o do ROS2:

- **`tf2_ros` & `tf2_geometry_msgs`**: Para gerenciar a √°rvore de transformadas (TF Tree).
    
- **`python3-ikpy`**: Motor de Cinem√°tica Inversa.
    
- **`robot_state_publisher`**: Para publicar o modelo est√°tico do rob√¥ baseado no URDF.
    
- **`cv_bridge` & `opencv`**: Processamento de imagem.
    

## üöÄ Como Executar

### Cen√°rio 1: O Desafio Completo (IK + TF)

Este launch carrega o URDF do rob√¥, publica as transformadas, calcula a posi√ß√£o da bola e move o rob√¥ usando cinem√°tica inversa.


``` Bash
ros2 launch robot_extra ik_challenge.launch.py
```

> **Fluxo de Opera√ß√£o:**
> 
> 1. Pressione `R` no terminal do teclado para ir para a posi√ß√£o inicial.
>     
> 2. Pressione `T` para iniciar o c√°lculo de trajet√≥ria at√© a bola detectada.
>     

### Cen√°rio 2: Visual Servoing com Profundidade

Uma abordagem alternativa que usa l√≥gica de controle proporcional (n√£o IK) para alinhar e aproximar.


``` Bash
ros2 launch robot_extra extra_challenge.launch.py
```

## üß† N√≥s (Nodes) Detalhados

### 1. `depth_estimator_node.py` (O Matem√°tico)

Este n√≥ √© respons√°vel por converter "pixels" em "metros" e "vis√£o" em "coordenadas de mundo".

- Matem√°tica (Pinhole Camera):
    
    Utiliza a rela√ß√£o de semelhan√ßa de tri√¢ngulos:
    
    $$ Z = \frac{f \cdot R_{real}}{R_{pixel}} $$
    
    Onde $f$ √© a dist√¢ncia focal, $R_{real}$ √© o raio f√≠sico da bola (7cm) e $R_{pixel}$ √© o raio detectado na imagem.
    
- Transforma√ß√£o TF2:
    
    O n√≥ escuta a transforma√ß√£o entre base_link e camera_link_optical. Quando detecta a bola, ele converte a posi√ß√£o $(x,y,z)$ da c√¢mera para a base do rob√¥ e publica no t√≥pico /vision/target_world_frame.
    

### 2. `ik_controller_node.py` (O Planejador)

Este n√≥ substitui o controle manual por planejamento de movimento.

- **Entrada:** Recebe um `PointStamped` com as coordenadas $(x, y, z)$ do alvo no referencial do mundo.
    
- **Processamento:**
    
    1. L√™ o estado atual dos motores (juntas).
        
    2. Utiliza `ikpy` carregando o URDF do UR5e.
        
    3. Calcula a solu√ß√£o IK para posicionar o efetuador final nas coordenadas recebidas.
        
- **Sa√≠da:** Publica `/ur5e/joint_targets` para mover o rob√¥.
    
- **Destaque:** Ele tamb√©m publica `/joint_states` para manter a √°rvore TF do ROS atualizada em tempo real.
    

### 3. `robot_controller_node.py` (Alternativa L√≥gica)

Um controlador reativo que n√£o usa IK, mas sim l√≥gica sequencial:

1. Gira a base para alinhar X.
    
2. Move o ombro para alinhar Y.
    
3. Estende o cotovelo para reduzir a diferen√ßa de profundidade ($Z_{atual} - Z_{alvo}$).
    

## üõ†Ô∏è Arquitetura de Transformadas (TF)

O sucesso deste pacote depende da correta configura√ß√£o do TF no arquivo `ik_challenge.launch.py`:

1. **`robot_state_publisher`**: L√™ o URDF e publica as transforma√ß√µes est√°ticas entre as juntas do bra√ßo.
    
2. **`static_transform_publisher`**: Cria o link inexistente entre o punho do rob√¥ (`wrist_3_link`) e a c√¢mera (`camera_link_optical`).
    
    - Ajuste fino realizado: Transla√ß√£o de `-5cm` em Z e rota√ß√£o para alinhar o eixo √≥ptico (Z-frente) com o eixo do rob√¥.
